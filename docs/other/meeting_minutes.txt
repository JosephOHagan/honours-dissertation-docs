29/09/17: Supervisor "Meeting" / Chat
Approached Dr. Williamson during a 3rd year lab as due to the hectic academic style life she missed my email to organise a meeting. Originally I was  going to send an email during the weekend but learned she happened to be running a lab at the same time I too was in the Boyd Orr. Took a chance in going direct to the source. It seemed to work.

Dr. Williamson gave a brief overview of the aims of the project. I'll be working with Debbie and Dennis (http://dennisanddebbie.club/) who'll serve as the client role. Debbie is the more technical of the two and Dennis the artist. Dr. Williamson said we'll need to mine them for requirements (as is the software engineering way)

I'll need to think about what I'll have to ask them. Their current work flow and development tools, how they imagine feature X and Y, etc. Dr. Williamson can probably help with that or at the very least ensure I don't forget to ask something completely obvious.

Project though is to develop toolkit which requires little to none technical experience. 

Current VR toolkits are apparently poorly documented and a technical nightmare for artists (Dr. Williamson had to reverse engineer one of them in order get something working)

She said I can probably take a look at some code / work which she has done previously to get a general idea of what I'm up against.

My project is to change that and make a toolkit that is easily usable by non-technical developers. 

Spoke briefly about some things I can do in preparation of our next meeting. She recommended three existing libraries (VRTK, Newton VR, SteamVR) to take a look at as well in addition to taking a general look at Unity and C#. I've a little experience with C# and Unity but will need a refresher on that. Wait I should make Word Scrumble in Unity as a refresher!

Dr. Williamson went over the key things to do before our next meeting - setup GitHub repo, meeting minutes and other documentation, setup dissertation template and suitable link dump for the dissertation. Do some general ready of existing tools and start playing with Unity & C#. 

She also mentioned that Unity projects and GitHub repos can be troublesome to work with at times. It won't be too bad as I'm the lone developer but I should play around with that beforehand.

They have Vives and Gear VRs though the project description stated aimed at mobile devices.

Anyway John Carmack is currently working on Gear VR and if John Carmack deems something important enough to be actively working on it then that's justification enough.

THEY ARE SETTING UP A VR LAB WITHIN THE SCHOOL.

That is rad.

Scheduled our first "proper" meeting for Thursday October 5th 2.30pm

######################################################################

05/10/17: Proper Supervisor Meeting

Note: We setup a regular meeting for Wednesday 2.30pm

Went over what I've done thus far in preparation. We also went over the key goals of the project once more in some more detail.

The VR lab has yet to be setup, academics are busy people, but they hope to have it setup within the next week. Book out time slots, etc. It's going to have a Vive!

Using Vive might have an effect on making some games in VR and other side effects - use the SteamVR camera. 
It will be worth looking into SteamVR more as well and reading up on that. 
I wonder if there was a Steam Dev Days talk on it? 
Surely...

I'll need to find out what exactly I need the VR lab for (aside from the obvious). 
What work can be done at home (think Christmas break, lab is booked, etc.) as I imagine quite a bit of it can be.

##
GENERAL IDEA / PROBLEMS WITH EXISTING TOOLS
As has been covered the general idea of the project is to make VR development as non-technical developer friendly as possible. 
No coding required if possible. 
Drag and drop this script here and you're set.

Despite tools like VRTK claiming to be user friendly and easy to use they still use a lot of Unity terminology, require lots of configuration to get up and running and often a lot of digging into code to get things running. 
That isn't not artist friendly. 

Newton VR was apparently HORRIBLE especially to work with for Dr. Williamson and D&D. 
The code base is supposedly a mess. 
They had multiple versions of the project working concurrently where a feature was implemented in on and tested to make sure everything was still working and if it was then transfer it over to the main project.
Even then you still would randomly fall through parts of the floor because some other object was configure with this object and that had this effect on that object other there. Oh look the floor is rising.
Not non-technical friendly.

Let's simplify this process to require as little technical input from the artists and developers as possible. 
Ideally no coding would be required on their part. 
Code free.
Instead of configuring multiple things how about we configure or set it up once and all that other work is taken care of on the back end
It all just works and is configured for you behind the scenes
How about we just drag and drop a pre-made script and that setups up the feature that we want
Dragging and dropping scripts
Developement via a user interface and a few clicks
Think about the time required and number of steps to add an object and make it interactable - let's make that as few steps and little time as possible
Stuff like that


ESTABLISHING DEFAULTS
Now the technical purists might scream at this but think of it as automatically setting up an object with a pre-established default (which I will determined). 
If they want more control then dig into the code and change the gravity variable value or whatever it is they want to change. 
But let's follow that idea of making it as code free as possible to setup the scene or desired feature with this pre-established default set of values and settings.
"It all works and here is what it does"

Example: Think about enabling the player's jump in a video game. 
Now in Halo the gravity set for the players jump is different and more floaty / moon-like than the gravity on the other objects in the game. 
Now the default "enable gravity" setting for an object would be your standard item in the game world which if enabled for the player would give them that gravity. 
In Halo this default gravity value would be tweaked by the developer within the code to give the floaty gravity the character has within the Halo games.
For most VR experiences a single gravity setting is probably fine but should creator wish to alter the player's gravity then they can by changing the code.
That's a bit of stretch as an example but it's an example I used to describe it to someone and I'm going to reuse it now.

So we're hiding all that config from the user and just giving them a default setup of "Here's your item setup to work with in this VR environment". 
It's less customisable but its solid and it works everytime. 
There's none of the one-off issues you might face where something just doesn't work because of the order you configure the items or because some other item is configure in a certain way, etc.

I do all the heavy lifting on the backend and provide a nice, clean, well designed UI to work with on the front end. 


SOUND LIBRARIES
Another key thing to look into is the sound / audio library. 
VRTK might not have this and the one in Newton didn't work at all for Dr. Williamson's project.
Either way there are quirks with the existing systems and mine will work properly. 
That can also be a key part of the project.

Example: When a ball makes contact with a surface it makes a noise. 
Why can't this be a drag and drop of an audio file and set under what conditions it plays?

I'll need to look into that some more but it sounds feasible.
At least the simple case of attaching a sound file for the ball to make noise when it collides.
Can't be that hard.
And even a simpy system which works is better than the competition's which is complex and broken.
That complexity just makes it harder to fix and setup.
My system is user friendly


END PRODUCT
Dr. Williamson also confirmed what I initially thought about the project and that is if good enough I get to release it on the Unity asset store, as an open source project, etc.
The other tools are... well I won't use the word she used but are too clunky and technical for your average artist or non-technical developer.
VR is in its infancy again (try to forget its first infancy in the 90s)
The tech is finally at a level where it's not a blocky, Tron-like world
We can make that but think about the difference between the original Tron and Tron Legacy
So I'm shipping the base, core model of a Virtual Reality Developement Toolkit for Unity in 6-7 months
Life called my bluff

##
The general plan for the next two weeks though is as follows:

2 weeks time have a requirements gathering session thingy with Debbie & Dennis:
	- Record the interview / chat and turn that into a plan for development
	- Get them to go through a code walkthrough so they can point and go "HATED THAT PART", etc.
	- Questions like "Can you give an example of a task you would want simplified", "What's the current process", etc.
	- Ask D&D what they want streamlined (it'll probably be dev-heavy but that's great because it looks and is more impressive!)
	- Record interview
	- Turn the recorded interview into a development plan - milestones (what do I want to achieve by Christmas / goal planning in that sense)

	
HELLO WORLD IN VR (PRACTICAL VR DEVELOPMENT)
I liked the idea of make a fireworks show in VR. 
But a Hello World in VR really should include something you can pick up and throw at a wall or the ground. 
Ideally it won't go through either. 
Of course there will be physics associated with the item. 
And it would be really cool if it made a noise on collision. 
Stuff like that.

DEVELOPMENT WORK & UNITY RESEARCH
Make some Unity games
Make some Unity VR games
Understand the process of developing and releasing a similar type of tool on the Unity asset store
General understanding of VR development and what Unity provides by default
Get a good grip on C#
 
## 
Questions and their Answers:

Question: Regarding an example of a task to simplify
Answer: 
This was answered pretty much before I got the chance to ask but it again highlights the non-developer nature of the project. 
For example to add one item might require configuring like 5 different things and then you still fall through portions of the floor. 
Let's simplify that to a few clicks, drag a script here and it's set. 
None of this configure A, B, C, oh and D is broken so configure P, Q, R, etc. configure once if at all. 

######################################################################

11/10/17: Proper Supervisor Meeting

There wasn’t much to discuss at today’s meeting. Just keep on becoming a game / VR developer.

I mentioned the continued attempt to get a hold of Unity and that as well as that I’ve prepared some questions but will need to continue with that.

I’ll probably throw those in a text file and write them in my notepad prior to the meeting.

Aside from that the lab is now going to be in the lab-type of room that’s in Dr. Williamson’s office. I assisted in clearing it with her. She also had musical chairs. Literally musical chairs. You sat on them and part of a song played. When everyone sat you got the entire band and the full song. Also the orb is moving. I did get to touch it though before it left. 

Our intention was to set up the Vive and dev environment but Graham didn’t send it over to her in time. We did go looking for it in his office but it appeared to still be connected and we couldn’t find the controllers.

We eventually tracked down Graham who said he’d send it over shortly. With that we pretty much ran out of time as she had to move the orb. It’s a very large and impressive orb. We did agree to meet  tomorrow again at 2.30 to learn how to use the Vive alongside the other student she is working who needs the Vive. We might play some VR games to make sure it works correctly. This is very important work. I hope I get to play Valve’s VR Lab game. Technically it was made with Unity. If not tomorrow then I’m sure I can persuade Dr. Williamson to allow me to do so around Christmas time. I should get her a card when the time comes.

######################################################################

12/10/17: Vive Setup Meeting

Dr. Williamson showed us how to setup the Vive. I then proceeded to spend the afternoon playing Vive games and getting a feel for using it.

Tilt Brush: We painted in 3D space. It's very strange to draw in 3 dimensions. You go to draw a straight horizontal line but it curves slightly because that's the way your hand and arm moves whilst making that motion. It's very strange.

Waltz of the Wizard: Another experience type of VR thingy. You get to play around in a wizards workshop. I threw Hadokens. Also this: [INSERT GIANT BOMB WIZARD VIDEO LINK] (sorry)

Rec Room: Rec Room is incredible. 
The ability to chat to other players is not this revolutionary concept but it's incredibly strange to interact and be in complete control of your avatar. 
It's that level of control that causes you to build a floating tower of chairs in the middle of a basketball court where you stand on top of the tower, catch chairs being thrown up to you by other players, continue to grow the tower by placing your caught chair on top and then teleporting on top of it before catching another chair and repeating. Turns out while you can stick your head through the ceiling the chairs cannot go through it.
Or how about entering with a team of four into a combat minigame. Running over to your downed squad mate, reviving him with a him fire and then firing and killing an enemy running up behind him while he simultaneously takes out one running up behind you. Then we fist bumped.
Rec Room is incredible.

######################################################################

18/10/17: Supervisor Meeting

TL;DR:

I scheduled a meeting with Debbie & Dennis for next week hopefully. I thought it was this week (my bad I should have followed up on that). If they can't attend then Dr. Williamson will just run me through the NewtonVR code and get an emailed list of requirements which should suffice. 

This week I gave an update on what I've been working on (Hello World VR opposed to Hello World Unity) and will need to continue to work on that and gain a further understanding in addition to figuring out the next few things I'll need for development of this project:
- Look at loading between scenes (without default Vive room)
- Look at GUI tool development
- Look at skyboxes (VR and non-VR)
- Look at event handling (VR and non-VR)
- Look at Unity camera (VR and non-VR)

There's also a few other documentation and planning type of things to produce:
- Make a rough estimate of a project development timeline
- Make a rough estimate of a development plan
- Create a project proposal / plan document (after meeting next week)


LOADING BETWEEN SCENES
One of the issues highlighted by Dr. Williamson with their application's development was loading between scenes.
One scene ends by triggering some event which transitions into a loading screen (developed by the user) which when the scene has loaded then transitions into the next scene.
Simply right?
Well not exactly. 
You shouldn't use the typical approach for scene transitions in Unity because the frame rate is at risk (kill the frame rate at a loading screen because it doesn't really matter and the resources are better spend elsewhere)
SteamVR instead has a method to load between scenes which transitions breifly to the default loading space (which happens to be the SteamVR home space or something)
Dr. Williamson couldn't get this to go straight to their own loading screen without first going here for a few seconds.
She combat this problem by just making the entire room black.
So you saw a few seconds of complete darkness before the actual loading screen kicked in.
It would be better to go straight to the loading screen.
I need to see how to change the default space used by SteamVR and make it easily changed if it isn't.
Asynchronous loading - look into that

GUI FRONT END TOOL DEVELOPMENT
The user should be able to interact with the scripts via a GUI menu (VRTK has its own menu component like the Unity Inspection menu)
I need to figure out how to create some simple example scripts which can be interacted with via this GUI
I've the idea of "established defaults" and so it would be great to be able to change the values in a menu opposed to digging through a script
I essentially need to learn how to make a Unity GUI tool and get it so it's able to change some established default value of the script its working with

CAMERA POSITIONING
Another issue I'm going to have to look at more is how the Unity camera works (in VR and non-VR applications)
One problem Dr. Williamson, Debbie and Dennis faced when developing their application was they wanted to start user with the camera facing the other way after a scene transitions
This was apparently a lot harder and more complex than it should have been
This also was an example of some of the challenges faced with the general camera controls, camera placement and camera movement
So this idea of changing a camera position / perspective both between scenes and during scene setup
I'm going to have to look into Unity cameras quite a bit

SKYBOXES
Yet another challenge faced by Dr. Williamson was changing the skybox of the scene
Some of the reasoning for this is explained below (TL;DR: Hard coded values and stub methods)
The best she could manage was to change one of the skyboxes to a nice solid red
Pity it wasn't meant to be red
I'll need to look into skyboxes some more
Bungie makes some incredible skyboxes. Also the Spyro games on the PlayStation 1 did as well. SkyHype.

EVENT HANDLING & OBJECT INTERACTION
Another thing to know about is event handling and object interaction
Working with actions which are assoicated with objects and interactions
Interacting with objects with more precision - giant cubes are very precise
The need for more complex and detailed / fine grained object interaction
The notion of interacting with an object to tigger some event (triggering events based off some user interaction)
Example - Push a button which start and stop a timer
Example - Push a button to spawn some items in the world
Example - Make it so when to specific objects collide that a certain particle display occurs
Example - Use a key to unlock a door

MISC DEVELOPMENT THINGS
Avatar movement - teleporting and walking around a space
Rendering - just rendering in general is something I'll need to know more about (fully understand the purpose of and how to use Valve's The Labratory renderer)

DEVELOPMENT PROCESS / TIMELINE
In terms of what to have done before Christmas, Dr. Williamson suggest getting a solid, easily extended framework in place and say 3-5 key features. Additional features can be easily slotted in and with this tool kit we can easily setup a new project, interact with some objects and easily transition between scenes with a custom loading screen.
There's the core set of features needed to get a project up and running. We build from that base.
In terms of shipping on the Unity asset store (see below) earlier is better as we can incorporate feedback and metrics into the report.
Launch early with key features and chip away and patch new features in rabidly. It'll need to have some unique / novel feature to get approval though. 
I'll need to look into that. 
This idea of a lightweight, easy to setup and allowing for fast development.
Perhaps its initial release is more developer focused in that in just handles some common SteamVR tasks and a few other novel things as well such as loading screens.
I'll need to think about / look into that.

TAG LINE
"It's everything SteamVR doesn't do"
Part of the problems faced with skyboxes, scene loading, etc. is that SteamVR contains some stub methods and hard coded values. 
In theory it should be possible to do what we are attempting to do its just that the method hasn't actually been implemented.
Or we can't change that colour because despite passing in the colour we want its actually hard coded so our passed in value is never used.
Apparently a lot of the problems faced are due to lack of or poor implementation.
It's my job to either fix that or make it much, much simpler (although perhaps slightly less flexible)

Question: What platforms to target?
In terms of MoSCoW: Vive is our Must have whereas Oculus is Should / Could Have depending on how development goes
I would like it to support both Oculus and Vive but time is a constraint. 
Perhaps that's my fun project once the Oculus Go is released.
Actually what am I doing at Christmas?
Vive primary focus (might play with Oculus after doing some reading)
That might be better as a separate tool though.
A machete over a swiss army knife. "That's not a knife. This is a knife!"
[GoT 5 vs. 1 (King Robert 5 vs 1 speech)]

Question: When should this thing be on the asset store?
You want to release it so that there's enough time to get some metrics and feedback.
This covers all the bases and your back in the report.
Shows that people are actually using the product and the feedback can help form the basis for future development. 
Aim for releasing earlier rather than later.
New features can always be patched in.
I need to find out what the timing is for getting approval of a Unity patch.
